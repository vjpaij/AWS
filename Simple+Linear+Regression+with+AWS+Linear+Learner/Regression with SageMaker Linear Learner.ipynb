{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M27qF7CTrBqc"
   },
   "source": [
    "# CODING TASK #1: UNDERSTAND THE PROBLEM STATEMENT/BUSINESS CASE [REVIEW]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNl52nl3qiyL"
   },
   "source": [
    "- In this project, we will assume that we own an ice cream business that is highly dependant on the outside air temperature. \n",
    "- We will apply simple linear regression to predict the daily revenue in dollars based on outside air temperature. \n",
    "- Dataset:\n",
    "    - Input (X): Outside Air Temperature\n",
    "    - Output (Y): Overall daily revenue generated in dollars \n",
    "- In simple linear regression, we predict the value of one variable Y based on another variable X.\n",
    "- X is called the independent variable and Y is called the dependant variable.\n",
    "- Why simple? Because it examines relationship between two variables only.\n",
    "- Why linear? when the independent variable increases (or decreases), the dependent variable increases (or decreases) in a linear fashion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #1 [OPTIONAL]:**\n",
    "- **What do you expect the relationship between outside air temperature and ice cream sales to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and bike sharing rental usage to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and ski rental usage to look like?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKmFmyaGunc7"
   },
   "source": [
    "# CODING TASK #2: IMPORT KEY LIBRARIES/DATASETS AND PREPARE THE DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we are using AWS SageMaker 2.72.1\n",
    "# We will be using the new SageMaker 2.x SDK \n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install seaborn library\n",
    "!pip install --upgrade Seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjIiJdM4u1IE"
   },
   "outputs": [],
   "source": [
    "# read the data using Pandas \n",
    "icecream_sales_df = pd.read_csv('IceCreamData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "q4_wPDKCu5Uc",
    "outputId": "886d2aaf-0205-4f46-96a7-629d0f367d2f"
   },
   "outputs": [],
   "source": [
    "# View the DataFrame\n",
    "icecream_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icecream_sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icecream_sales_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OXZB2F21e4H"
   },
   "outputs": [],
   "source": [
    "# Separate the data into input X and Output y\n",
    "X = icecream_sales_df[['Temperature']]\n",
    "y = icecream_sales_df[['Revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XpGU63Ne1e9P",
    "outputId": "e16c74ca-dc1c-416c-dc44-7f927bb99bc6"
   },
   "outputs": [],
   "source": [
    "# Check out the shape of the input\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OjGj0RALA0qZ",
    "outputId": "26559a6c-880b-45b4-a1e8-3c4b92bea889"
   },
   "outputs": [],
   "source": [
    "# Check out the shape of the output\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIeiK1maA6mm"
   },
   "outputs": [],
   "source": [
    "# Convert the datatype to float32\n",
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take the numerical variables and scale them\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoReLFfnA6uF"
   },
   "outputs": [],
   "source": [
    "# split the data into training and testing using SkLearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #2 [OPTIONAL]:**\n",
    " - **Split the data into 75% for training and the rest for testing**\n",
    " - **Verify that the split was successful**\n",
    " - **Did you notice any change in the order of the data? why?**\n",
    " - **Add an attribute to disable data shuffling [external research is required]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #3: TRAIN A LINEAR LEARNER MODEL USING AWS SAGEMAKER (SDK 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Let's define the S3 bucket and prefix that we want to use in this session\n",
    "bucket = 'aws.ml.engineer' # bucket need to be created beforehand\n",
    "prefix = 'linear_learner' # prefix is the subfolder within the bucket.\n",
    "\n",
    "# Let's get the execution role for the notebook instance. \n",
    "# This is the IAM role that you created when you created your notebook instance. You pass the role to the training job.\n",
    "# Note that AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume to perform tasks on your behalf (for example, reading training results, called model artifacts, from the S3 bucket and writing training results to Amazon S3). \n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io # The io module allows for dealing with various types of I/O (text I/O, binary I/O and raw I/O). \n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac # sagemaker common libary\n",
    "\n",
    "# Code below converts the data in numpy array format to RecordIO format\n",
    "# This is the format required by Sagemaker Linear Learner (one of many available options!)\n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it\n",
    "# Let's reset that back to zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Code to upload RecordIO data to S3\n",
    " \n",
    "# Key refers to the name of the file    \n",
    "key = 'linear-train-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the training data location in s3\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the target label is a vector\n",
    "y_test = y_test[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to upload RecordIO data to S3\n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_test, y_test)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it\n",
    "# Let's reset that back to zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key refers to the name of the file    \n",
    "key = 'linear-test-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the testing data location in s3\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output placeholder in S3 bucket to store the linear learner output\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this code leverages the new SageMaker SDK 2.0\n",
    "# Check this out for the list of changes from AWS SageMaker SDK 1.0 to 2.0: https://sagemaker.readthedocs.io/en/stable/v2.html\n",
    "\n",
    "# This code is used to get the training container of sagemaker built-in algorithms\n",
    "# all we have to do is to specify the name of the algorithm that we want to use\n",
    "\n",
    "# Let's obtain a reference to the linearLearner container image\n",
    "# You don't have to specify (hardcode) the region, get_image_uri will get the current region name using boto3.Session\n",
    "container = sagemaker.image_uris.retrieve(\"linear-learner\", boto3.Session().region_name)\n",
    "\n",
    "\n",
    "# If you are using an old version of AWS SageMAker SDK 1.0, you need to use get_image_uri\n",
    "# from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "# container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this code leverages the new SageMaker SDK 2.0\n",
    "# Check this for the list of changes from AWS SageMaker SDK 1.0 to 2.0: https://sagemaker.readthedocs.io/en/stable/v2.html\n",
    "\n",
    "\n",
    "# We have pass in the container, the type of instance that we would like to use for training \n",
    "# output path and sagemaker session into the Estimator. \n",
    "# We can also specify how many instances we would like to use for training\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 5,\n",
    "                           num_models = 32,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #3 [OPTIONAL]:**\n",
    "- **Try to train the model with more epochs and additional number of models**\n",
    "- **Can you try to reduce the cost of the billable seconds?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #4: DEPLOY AND TEST TRAINED LINEAR LEARNER MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying the model to perform inference \n",
    "# serializer: A serializer object is used to encode data for an inference endpoint.\n",
    "# deserializer: A deserializer object is used to decode data from an inference endpoint.\n",
    "\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "\n",
    "linear_regressor = linear.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m4.xlarge',\n",
    "                                 serializer = CSVSerializer(),\n",
    "                                 deserializer = JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use code lines below if you're using AWS SDK 1.0\n",
    "# from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "# linear_regressor.content_type = 'text/csv' # This will need to be enabled for AWS SageMaker SDK 1.0\n",
    "# linear_regressor.serializer = csv_serializer\n",
    "# linear_regressor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction on the test data\n",
    "\n",
    "result = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result # results are in Json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the result is in json format, we access the scores by iterating through the scores in the predictions\n",
    "\n",
    "predictions = np.array([r['score'] for r in result['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE TEST SET RESULTS\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.scatter(X_test, y_test, color = 'blue')\n",
    "plt.plot(X_test, predictions, color = 'red')\n",
    "plt.xlabel('Temperature [DegC]')\n",
    "plt.ylabel('Revenue [$]')\n",
    "plt.title('Temperature vs. Revenue (Testing Dataset)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "linear_regressor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #4 [OPTIONAL]:**\n",
    "- **Use the trained AWS SageMaker Linear Learner model, obtain the revenue when the outside air temperature is 35 degC and 10 degC?**\n",
    "- **Compare the results to the ones optained using SkLearn!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREAT JOB! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICE OPPORTUNITY SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #1 SOLUTION:**\n",
    "- **What do you expect the relationship between outside air temperature and ice cream sales to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and bike sharing rental usage to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and ski rental usage to look like?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A positive correlation is expected for case 1 & 2 since as temperature increases, we expect ice cream sales and bike sharing rental usage to increase as well. \n",
    "- A positive correlation implies a positive relationship between X and Y: as X increases, Y increases.\n",
    "- A Negative correlation expected for case 3 (ski rental usage) since as temperature decreases, ski rental usage tend to increase (to a point when it's too cold and demand should stabilize or even drop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #2 SOLUTION:**\n",
    " - **Split the data into 75% for training and the rest for testing**\n",
    " - **Verify that the split was successful**\n",
    " - **Did you notice any change in the order of the data? why?**\n",
    " - **Add an attribute to disable data shuffling [external research is required]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing using SkLearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #3 SOLUTION:**\n",
    "- **Try to train the model with more epochs and additional number of models**\n",
    "- **Can you try to reduce the cost of the billable seconds?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More epochs and additional number of models\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 10,\n",
    "                           num_models = 64,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Spot offers a lower price compared to an on-Demand instance.\n",
    "# Amazon EC2 Spot Instances offer spare compute capacity available in the AWS Cloud at ~90% discounts compared to On-Demand prices. \n",
    "\n",
    "# train_use_spot_instances (bool): Specifies whether to use SageMaker Managed Spot instances for training.\n",
    "# max_run (int): Timeout in seconds for training (default: 24 * 60 * 60). After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "# max_wait (int): Timeout in seconds waiting for spot training instances (default: None). After this amount of time Amazon SageMaker will stop waiting for Spot instances to become available (default:None).\n",
    "\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session,\n",
    "                                       use_spot_instances = True,\n",
    "                                       max_run = 300,\n",
    "                                       max_wait = 600)\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 5,\n",
    "                           num_models = 32,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #4 SOLUTION:**\n",
    "- **Use the trained AWS SageMaker Linear Learner model, obtain the revenue when the outside air temperature is 35 degC and 10 degC?**\n",
    "- **Compare the results to the ones optained using SkLearn!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = [[10]]\n",
    "revenue = linear_regressor.predict(temperature)\n",
    "print(revenue)\n",
    "\n",
    "temperature = [[35]] \n",
    "revenue = linear_regressor.predict(temperature)\n",
    "print(revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "linear_regressor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graduate_Admission_Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
